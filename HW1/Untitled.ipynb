{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7278e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor, GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbf8897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>LSAT</th>\n",
       "      <th>UGPA</th>\n",
       "      <th>ZFYA</th>\n",
       "      <th>sander_index</th>\n",
       "      <th>first_pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21791.000000</td>\n",
       "      <td>21791.000000</td>\n",
       "      <td>21791.000000</td>\n",
       "      <td>21791.000000</td>\n",
       "      <td>21791.000000</td>\n",
       "      <td>21791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.562342</td>\n",
       "      <td>36.772383</td>\n",
       "      <td>3.226589</td>\n",
       "      <td>0.096426</td>\n",
       "      <td>0.766949</td>\n",
       "      <td>0.888440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496110</td>\n",
       "      <td>5.446659</td>\n",
       "      <td>0.414182</td>\n",
       "      <td>0.932631</td>\n",
       "      <td>0.086736</td>\n",
       "      <td>0.314831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.350000</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>0.711607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.769643</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sex          LSAT          UGPA          ZFYA  sander_index  \\\n",
       "count  21791.000000  21791.000000  21791.000000  21791.000000  21791.000000   \n",
       "mean       1.562342     36.772383      3.226589      0.096426      0.766949   \n",
       "std        0.496110      5.446659      0.414182      0.932631      0.086736   \n",
       "min        1.000000     11.000000      0.000000     -3.350000      0.387500   \n",
       "25%        1.000000     33.000000      3.000000     -0.550000      0.711607   \n",
       "50%        2.000000     37.000000      3.300000      0.090000      0.769643   \n",
       "75%        2.000000     41.000000      3.500000      0.750000      0.827381   \n",
       "max        2.000000     48.000000      4.200000      3.480000      1.000000   \n",
       "\n",
       "           first_pf  \n",
       "count  21791.000000  \n",
       "mean       0.888440  \n",
       "std        0.314831  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('law_data.csv',index_col=0)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b7872c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(17432, 16), (4358, 16)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSAT</th>\n",
       "      <th>UGPA</th>\n",
       "      <th>region_first</th>\n",
       "      <th>ZFYA</th>\n",
       "      <th>sander_index</th>\n",
       "      <th>first_pf</th>\n",
       "      <th>amerindian</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>mexican</th>\n",
       "      <th>other</th>\n",
       "      <th>puertorican</th>\n",
       "      <th>white</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>GL</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.782738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>GL</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>MS</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.670238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.697024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>GL</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>0.786310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22478</th>\n",
       "      <td>40.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>SC</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22479</th>\n",
       "      <td>44.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>SC</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22480</th>\n",
       "      <td>31.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>SC</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.749405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22481</th>\n",
       "      <td>42.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>SC</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22482</th>\n",
       "      <td>35.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>SC</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.761310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17432 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LSAT  UGPA region_first  ZFYA  sander_index  first_pf  amerindian  \\\n",
       "0      39.0   3.1           GL -0.98      0.782738       1.0           0   \n",
       "1      36.0   3.0           GL  0.09      0.735714       1.0           0   \n",
       "2      30.0   3.1           MS -0.35      0.670238       1.0           0   \n",
       "5      39.0   2.2           NE  0.58      0.697024       1.0           0   \n",
       "6      37.0   3.4           GL -1.26      0.786310       1.0           0   \n",
       "...     ...   ...          ...   ...           ...       ...         ...   \n",
       "22478  40.0   2.7           SC  0.22      0.757143       1.0           0   \n",
       "22479  44.0   2.6           SC  0.84      0.797619       1.0           0   \n",
       "22480  31.0   3.8           SC -0.65      0.749405       1.0           0   \n",
       "22481  42.0   3.8           SC  0.84      0.886905       1.0           0   \n",
       "22482  35.0   3.4           SC  0.91      0.761310       1.0           0   \n",
       "\n",
       "       asian  black  hispanic  mexican  other  puertorican  white  male  \\\n",
       "0          0      0         0        0      0            0      1     0   \n",
       "1          0      0         0        0      0            0      1     0   \n",
       "2          0      0         0        0      0            0      1     1   \n",
       "5          0      0         1        0      0            0      0     1   \n",
       "6          0      0         0        0      0            0      1     0   \n",
       "...      ...    ...       ...      ...    ...          ...    ...   ...   \n",
       "22478      0      0         0        0      0            0      1     1   \n",
       "22479      0      0         0        0      0            0      1     1   \n",
       "22480      0      0         0        0      0            0      1     0   \n",
       "22481      0      0         0        0      0            0      1     0   \n",
       "22482      0      0         0        0      0            0      1     1   \n",
       "\n",
       "       female  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  \n",
       "5           0  \n",
       "6           1  \n",
       "...       ...  \n",
       "22478       0  \n",
       "22479       0  \n",
       "22480       1  \n",
       "22481       1  \n",
       "22482       0  \n",
       "\n",
       "[17432 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def onehottify(df):\n",
    "    #based on the data formatting in the original code repo https://github.com/mkusner/counterfactual-fairness/blob/master/law_school_classifiers.R\n",
    "    df = df[df.region_first != 'PO'].copy()\n",
    "    df = df.copy()\n",
    "    #one-hot encode race and gender\n",
    "    race_df = pd.get_dummies(df['race'])\n",
    "    for col in race_df.columns:\n",
    "        df[col.lower()] = race_df[col].values\n",
    "    df['male'] = df.sex.apply(lambda x: int(x == 2))\n",
    "    df['female'] = df.sex.apply(lambda x: int(x == 1))\n",
    "    df = df.drop(['race','sex'],axis=1)\n",
    "    #train-test split (original split is done via an R-function and isn't pre-provided)\n",
    "    #original code filters first_pf = 1 for train data (I don't know why)\n",
    "    df_train = df.iloc[0:int(df.shape[0]*.8)]\n",
    "    df_test = df.drop(df_train.index,axis=0)\n",
    "    return df_train, df_test\n",
    "\n",
    "train, test = onehottify(data)\n",
    "print([train.shape,test.shape])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86dd520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protected_cols():\n",
    "    return ['male','female','amerindian','asian','black','hispanic','mexican','other','puertorican','white']\n",
    "\n",
    "def unprotected_cols():\n",
    "    return ['LSAT','UGPA']\n",
    "\n",
    "def ycol():\n",
    "    return ['ZFYA']\n",
    "\n",
    "def lr():\n",
    "    return LinearRegression()\n",
    "\n",
    "def rmse(x,x2):\n",
    "    return np.sqrt(np.mean((x - x2)**2))\n",
    "\n",
    "def normalize(xtrain,xtest):\n",
    "    mean = xtrain.mean(axis=0)\n",
    "    std = xtrain.std(axis=0)\n",
    "    norm = lambda x: (x - mean)/std\n",
    "    return norm(xtrain),norm(xtest)\n",
    "\n",
    "def make_split(dtrain,dtest,xcols,yvar):\n",
    "    xtrain = dtrain[xcols].astype(float)\n",
    "    xtest = dtest[xcols].astype(float)\n",
    "    ytrain = dtrain[yvar].astype(float)\n",
    "    ytest = dtest[yvar].astype(float)\n",
    "    xtrain, xtest = normalize(xtrain,xtest)\n",
    "    return xtrain, xtest, ytrain, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020fd70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.05884847],\n",
       "        [ 0.34801669],\n",
       "        [ 0.34801669],\n",
       "        ...,\n",
       "        [ 0.31648194],\n",
       "        [-0.02759233],\n",
       "        [-0.07595873]]),\n",
       " 0.8774416616997881)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unfair_aware_model(dtrain,dtest):\n",
    "    cols = protected_cols() + unprotected_cols()\n",
    "    xtrain, xtest, ytrain, ytest = make_split(dtrain,dtest,cols,ycol())\n",
    "    model = lr()\n",
    "    model.fit(xtrain.values,ytrain.values)\n",
    "    ypred = model.predict(xtest.values)\n",
    "    return ypred, rmse(ypred,ytest.values)\n",
    "\n",
    "unfair_aware_model(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee5c780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.05815671],\n",
       "        [ 0.30538129],\n",
       "        [ 0.30538129],\n",
       "        ...,\n",
       "        [ 0.28900084],\n",
       "        [-0.21824016],\n",
       "        [-0.29313182]]),\n",
       " 0.9020494345037581)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unfair_unaware_model(dtrain,dtest):\n",
    "    cols = unprotected_cols()\n",
    "    xtrain, xtest, ytrain, ytest = make_split(dtrain,dtest,cols,ycol())\n",
    "    model = lr()\n",
    "    model.fit(xtrain.values,ytrain.values)\n",
    "    ypred = model.predict(xtest.values)\n",
    "    return ypred, rmse(ypred,ytest.values)\n",
    "\n",
    "unfair_unaware_model(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557eee5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.04684315],\n",
       "        [ 0.22009449],\n",
       "        [ 0.22009449],\n",
       "        ...,\n",
       "        [ 0.20928633],\n",
       "        [-0.15796058],\n",
       "        [-0.20862172]]),\n",
       " 0.9290829349674626)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_residual(dtrain,dtest,y):\n",
    "    cols = protected_cols()\n",
    "    xtrain, xtest, ytrain, ytest = make_split(dtrain,dtest,cols,[y])\n",
    "    model = lr()\n",
    "    model.fit(xtrain.values,ytrain.values)\n",
    "    train_ypred = model.predict(xtrain.values)\n",
    "    test_ypred = model.predict(xtest.values)\n",
    "    \n",
    "    train_residual = ytrain - train_ypred\n",
    "    test_residual = ytest - test_ypred\n",
    "    \n",
    "    return train_residual.values, test_residual.values\n",
    "\n",
    "def fair_deterministic_model(dtrain,dtest):\n",
    "    dtrain = dtrain.copy()\n",
    "    dtest = dtest.copy()\n",
    "    gpa_res_train, gpa_res_test = score_residual(dtrain,dtest,'UGPA')\n",
    "    lsat_res_train, lsat_res_test= score_residual(dtrain,dtest,'LSAT')\n",
    "    \n",
    "    dtrain['gpa_residual'] = gpa_res_train\n",
    "    dtrain['lsat_residual']=  lsat_res_train\n",
    "    dtest['gpa_residual'] = gpa_res_test\n",
    "    dtest['lsat_residual'] = lsat_res_test\n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = make_split(dtrain,dtest,['gpa_residual','lsat_residual'],ycol())\n",
    "    model = lr()\n",
    "    model.fit(xtrain.values,ytrain.values)\n",
    "    ypred = model.predict(xtest.values)\n",
    "    return ypred, rmse(ypred,ytest.values)\n",
    "\n",
    "fair_deterministic_model(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c940916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pgmpy\\models\\BayesianModel.py:8: FutureWarning: BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\network\\network.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].map(self._node_states[col])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\causalnex\\utils\\data_utils.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.fillna(placeholder, inplace=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pgmpy\\factors\\discrete\\CPD.py:332: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tabular_cpd.values = (cpd / cpd.sum(axis=0)).reshape(tabular_cpd.cardinality)\n"
     ]
    }
   ],
   "source": [
    "from causalnex.structure import StructureModel\n",
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
    "from IPython.display import Image\n",
    "from causalnex.estimator.em import EMSingleLatentVariable\n",
    "from causalnex.network import BayesianNetwork\n",
    "\n",
    "def find_latent_knowledge(dtrain,dtest):\n",
    "#     df = pd.concat([dtrain.copy(),dtest.copy()],axis=0)\n",
    "    df = dtrain.copy()\n",
    "    df = df[protected_cols() + unprotected_cols() + ycol()].astype(float)\n",
    "    sm = StructureModel()\n",
    "    edges = []\n",
    "    for col in protected_cols():\n",
    "        for col2 in unprotected_cols():\n",
    "            edges.append((col,col2))\n",
    "    sm.add_edges_from(edges)\n",
    "    bn = BayesianNetwork(sm)\n",
    "    bn.fit_node_states_and_cpds(df)\n",
    "    bn.add_node(node='u',edges_to_add=[('u',l) for l in unprotected_cols()],edges_to_remove=[])\n",
    "    options= list(np.linspace(-.99,.99))\n",
    "    boundaries = EMSingleLatentVariable.get_default_box(\n",
    "        sm=bn.structure,\n",
    "        node_states={\n",
    "            **bn.node_states,\n",
    "            'u': set(options)\n",
    "        },\n",
    "        lv_name='u'\n",
    "    )\n",
    "    priors = EMSingleLatentVariable.get_default_priors(\n",
    "        sm=bn.structure,\n",
    "        node_states={\n",
    "            **bn.node_states,\n",
    "            'u': set(options)\n",
    "        },\n",
    "        lv_name='u'\n",
    "    )\n",
    "    bn.fit_latent_cpds(\n",
    "        lv_name='u',\n",
    "        lv_states=options,\n",
    "        data=df,\n",
    "        box_constraints=boundaries,\n",
    "        priors=priors,\n",
    "        n_runs=3,\n",
    "    )\n",
    "    return bn\n",
    "\n",
    "test = find_latent_knowledge(train,test)\n",
    "test.cpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85680b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99      , -0.94959184, -0.90918367, -0.86877551, -0.82836735,\n",
       "       -0.78795918, -0.74755102, -0.70714286, -0.66673469, -0.62632653,\n",
       "       -0.58591837, -0.5455102 , -0.50510204, -0.46469388, -0.42428571,\n",
       "       -0.38387755, -0.34346939, -0.30306122, -0.26265306, -0.2222449 ,\n",
       "       -0.18183673, -0.14142857, -0.10102041, -0.06061224, -0.02020408,\n",
       "        0.02020408,  0.06061224,  0.10102041,  0.14142857,  0.18183673,\n",
       "        0.2222449 ,  0.26265306,  0.30306122,  0.34346939,  0.38387755,\n",
       "        0.42428571,  0.46469388,  0.50510204,  0.5455102 ,  0.58591837,\n",
       "        0.62632653,  0.66673469,  0.70714286,  0.74755102,  0.78795918,\n",
       "        0.82836735,  0.86877551,  0.90918367,  0.94959184,  0.99      ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(-.99,.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7227a792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
